
% taken from http://physics.clarku.edu/sip/tutorials/TeX/intro.html

\documentclass[12pt]{article}

\usepackage{amsmath}    % need for subequations
\usepackage{graphicx}   % need for figures
\usepackage{verbatim}   % useful for program listings
\usepackage{color}      % use if color is used in text
\usepackage{hyperref}   % use for hypertext links, including those to external documents and URLs
\usepackage{listings}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
% don't need the following. simply use defaults
\setlength{\baselineskip}{16.0pt}    % 16 pt usual spacing between lines

\setlength{\parskip}{3pt plus 2pt}
\setlength{\parindent}{20pt}
\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\marginparsep}{0.75cm}
\setlength{\marginparwidth}{2.5cm}
\setlength{\marginparpush}{1.0cm}
\setlength{\textwidth}{150mm}

\begin{comment}
\pagestyle{empty} % use if page numbers not wanted
\end{comment}

% above is the preamble

\begin{document}

\begin{center}
{\large A Comprehensive Comparison of C++ and R} \\ % \\ = new line
\copyright 2020 by Cang, K. and Navarez, A. \\
November 2020
\end{center}

\tableofcontents
\newpage

\section{R}
\subsection{Purpose and Motivations}
Fundamentally, R is a dialect of S. It was created to do away with the limitations of S, which is that it is only available commercially.
\subsection{History (Authors, Revisions, Adoption)}
\subsubsection{S, the precursor of R}
S is a language created by John Chambers and others at Bell Labs on 1976. The purpose of the language was to be an internal statistical analysis environment. The first version was implemented by using FORTRAN libraries. This was later changed to C at S version 3 (1988), which resembles the current systems of R.

On 1988, Bell labs provided StatSci (which was later named Insigthful Corp.) exclusive license to develop and sell the language. Insightful formally gained ownership of S when it purchased the language from Lucent for \$ 2,000,000, and created the language as a product called S-PLUS. It was names so as there were additions to the features, most of which are GUIs.

\subsubsection{R}
R was created on 1991 by Ross Ihaka and Robert Gentleman of the University of Auckland as an implementation of the S language. It was presented to the 1996 issue of the \textit{Journal of Computational and Graphical Statistics} as a ``language for data analysis and graphics''. It was made free source when Martin Machler convinced Ross and Robert to include R under the GNU General Public License.

The first R developer groups were in 1996 with the establishment of R-help and R-devel mailing lists. The R Core Group was formed in 1997 which included associates which come from S and S-PLUS. The group is in charge of controlling the source code for the language and checking changes made to the R source tree.

R version 1.0.0 was publicly released in 2000. As of the moment of writing this paper, the R is in version 4.0.3.
\subsection{Language Features}
R as a language follows the philosophy of S, which was primarily developed for data analysis rather than programming. Both S and R have interactive environment that could easily service both data analysis (skewed to command-line commands) and longer programs (following traditional programming). R has the following features:
\begin{itemize}
\item Runs in almost every standard computing platform  and operating systems
\item Open-source
\item An effective data handling and storage facility
\item A suite of operators for calculations on array, in particular matrices
\item A large, coherent, integrated collection of intermediate tools for data analysis
\item Graphical facilities for data analysis and display either on-screen or on hardcopy u
\item Well-developed, simple, and effective programming language which includes conditionals, loops, user-defined recursive functions and input and output facilities.
\item Can be linked to C, C++, and Fortran for computationally-intensive tasks
\item A broad selection of packages available in the CRAN sites which cater a wide variety of modern statistics
\item An own LaTex-like documentation format to supply comprehensive documentation
\item Active community support
\end{itemize}

\subsection{Paradigm(s)}
\subsection{Language Evaluation Criteria}

\subsubsection{Data Types}
This section shall cover and critique the fundamental data objects and values found in R.

\textbf{Atomic Objects} As R abides by the principle that everything is an object, there are no ``data types'', per se. However, there are five basic objects which serve as the building blocks of other complex objects in the language. The objects are given by the table below:

\begin{table}[h!]
  \begin{center}
    \caption{Atomic Classes of Objects in R}
    \label{tab:table1}
    \begin{tabular}{|l|c|l|}
      \toprule % toprule here
      \textbf{Object Name} & \textbf{Sample Values} & \textbf{Stored as}\\
      \midrule % midrule here
      character & char, ``another char'' & character \\
      \hline
      numeric (real) & 2, 1.0 & numeric \\
      \hline
      integer & 1L, 22L & integer \\
      \hline
      complex & 1 + 2i, 2 - 11i & complex \\
      \hline
      logical & True, T, False, F & logical \\
      \hline
      raw & ``Hello'' which is stored as 48 65 6c 6c 6f& raw \\
      \bottomrule
    \end{tabular}
  \end{center}
\end{table}

It must also be noted that vectors are the most basic type of objects in R. Hence, these atomic objects are actually vectors of length 1. A more detailed analysis on the effects of vectors will be discussed further sections.

Majority of the atomic objects are intuitive in nature, however some are affected by the peculiarities of the language. By default, R treats numbers as numeric types, which are implemented as double precision real. This can be very useful if one is dealing with large numbers as the memory allocated to double precision is suitable, however it would be too much if numbers which fall within the short or integer range are used. To declare an integer, one must add L as a suffix to the number, as seen in the table - this may positively affect readability as one can distinctly separate the integers and the non-integers, however writability suffers as forgetting the suffix means that the number is type casted into numeric, which may happen when one writes long code in the language. Another issue on readability and writability is the allowing of T and F to stand for True and False in logical values - this causes ambiguity in the sense that a single construct is implemented in two way, and it may be confused with a variable, much like this snippet of code which does not produce errors when T is given a value:

\begin{lstlisting}[frame=single]
  > T #T as a logical value
  [1] True
  > T <- 22 #T as a variable, does not raise errors/warnings
  > T
  [1] 22
\end{lstlisting}

Additionally, R was also designed with no separate string object, thereby eroding the distinction between characters (which are implemented generally as single characters) and strings (which may contain zero or more characters).

For composite objects, R has vectors, matrices, names, lists, and data frames. \\

\textbf{Vectors.} As stated earlier, vectors are the most basic objects in R. Vectors, much like the implementations of languages such as C and Java, are collections of objects with the same type. Some special vectors included the atomic objects and vectors with a length of 0. If type-checked, a vector will reflect the data type of its values. Implementations of vectors can be done using the following syntax:

\begin{lstlisting}[frame=single]
  > vec <- c(1,2,3) #using c()
  > vec
  [1] 1 2 3
  > class(vec)
  [1] numeric
  > vec2 <- vector(mode=''numeric'', length= 3L) #by vector()
  > vec2 #uniform values vector
  [1] 0 0 0
  > class(vec2)
  [1] numeric
  > vals <- c(4,5,6)
  > vec3 <- as.vector(vals) #explicit coercion
  > vec3
  [1] 4 5 6
  > class(vec)
  [1] numeric
\end{lstlisting}

This again raises the issue of ambiguity, as vectors can be implemented in three different ways. Writability suffers as even though programmers may choose a single implementation, the three methods' use cases do not directly intersect with each other (vector() creates a vector of uniform values, c() is the most generic implementation but does not directly handle uniform values, and as.vector() is an explicit coercion to a vector). Readability also suffers with the usage of c(), as the function names is not self-documenting.\\

\textbf{Matrices.} Matrices are two-dimensional vectors, with the dimension as an attribute of length 2 comprised of the number of rows and number of columns. The implementation is done using the following syntax:

\begin{lstlisting}[frame=single]
  > matr <- matrix(data=1:4, nrow=2, ncol=3) #using matrix()
  > matr #matrix of NAs
      [,1] [,2]
  [1,]  1    3
  [2,]  2    4
  > matr2 <- 1:4
  > dim(matr2) <- c(2,2) #adding dims to vector
  > matr2
      [,1] [,2]
  [1,]  1    3
  [2,]  2    4
  > x <- 1:2
  > y <- 3:4
  > matr3 <- rbind(x,y) #row binding vectors
  > matr3
      [,1] [,2]
  x     1    2
  y     3    4
  > matr4 <- cbind(x,y) #column binding vectors
  > matr4
        x    y
  [1,]  1    2
  [2,]  3    4
\end{lstlisting}

Similar to vectors, the multiple implementations with different use cases negatively affects both readability and writability as the programmer needs to remember each implementation.\\

\textbf{Lists.} Lists are special vectors that can hold values of different classes. The implementation is done using the following syntax:

\begin{lstlisting}[frame=single]
  > list1 <- list(1, 2L, True, ``list'') #using list()
  > list1
  [[1]]
  [1]  1

  [[2]]
  [1] 2

  [[3]]
  [1] True

  [[4]]
  [1] ``list''
  > list2 <- vector(``list'', length=4) #using vector()
  > list2 #empty list of specified length
  [[1]]
  NULL

  [[2]]
  NULL

  [[3]]
  NULL

  [[4]]
  NULL
\end{lstlisting}

In this case, one can see heavy ambiguity with the use of vector(). Although a list is a type of vector, using vector() to create a NULL list defeats the purpose of having a separate list function. In turn, it aids somehow aids writability as a programmer can use one function, but negatively affects readability, even with the passing of the ``list'' argument.\\

\textbf{Factors.} Factors represent categorical data, with or without order. This data class is important for statistical modeling. The sole implementation is given by the syntax:

\begin{lstlisting}[frame=single]
  > x <- factor(c(``red'', ''blue'', ``red'', ``red''))
  > x
  [1] red blue red red
  Levels: blue red
\end{lstlisting}

Only one implementation enhances writability as a programmer would not need to memorize multiple syntax to create factors; it negatively affects readability as the programmer needs to memorize yet another data class, albeit necessary.\\

\textbf{Data Frames.} Data frames are implemented as a special type of list with each element having the same length, which is intuitive as it is used to read tabular data. Each element (specifically, column) only has one class, but the columns may have different classes from each other. This data class is implemented by the given syntax:

\begin{lstlisting}[frame=single]
  > df <- data.frame(nums=1:4, letters=c(``a'',''b'',''c'',
                      ''d''))
  > df
     nums  letters
  1    1         a
  2    2         b
  3    3         c
  4    4         d
\end{lstlisting}

Only one implementation enhances writability as a programmer would not need to memorize multiple syntax to create data frames; it negatively affects readability as the programmer needs to memorize yet another data class, albeit necessary.\\

\textbf{Special Data Values.} As R is fundamentally a statistical language, it contains other values which are integral in processing data, such as:
\begin{description}
\item[NA] stands for ``Not Available'' as an indicator for missing values. It can have classes to (except raw)
\item[NaN] stands for ``Not a Number'' which applies to numerical, and complex (real, imaginary) values, but not to integer vector values.
\item[NULL] is an object which is returned when an expression/function returns an undefined value.
\item[Inf/-Inf] stands for infinity which entails very large values or the quotient of dividing a number by 0.
\end{description}

In strengthens readability as each value covers distinct contexts, making them very readable for the programmer. On the other hand, writability suffers as programmers must memorize more values to suit their needed cases.

\subsubsection{Binding, Scoping, Referencing}
  Explicit type definitions are not required for variables and functions
  R checks type compatability during runtime, and performs conversions, when possible
  R is lexically scoped until noted
  R associates attributes to all data structures, used as books for many purposes
  With the undertones of functional programming languages, scoping is lexical, there is no difference between variables and functions
  Dynamic Binding

  dynamic typed
  dynamic evaluation
  text to unevaluated expressions using quote()
  variable substitution substitute()
  partial substitution bquote()
  expression to text substitute()/deparse()

\subsubsection{Expressions}
Syntax
Precedence rules
Overloaded Operations
Type conversions, relational, and boolean operators
% && & || |, implicit conversions are done most of the time, but explicit conversions can be done
Expressions

\subsubsection{Statements and Control Structures}
Assignment Statements
Procedure Calls
Conditional Statements
Iterative Statements
Concurrent Statements
Sequential Statements

<- local assignment introduces new symbols/updates exsiting in the current frame; is local
<<- operates on the rest of the environment, ignores local values, updates the first value anywhere in the environment, or define a new binding for x at the top-level


\subsubsection{Procedures and Subprograms}
Subparameters
Simple Call returns
Recursive Procedures
Coroutines

Exception Handling
Paramater-Passing Methods
Parameters which are subprograms

Design Issues and Functions
Overloaded and Generic Subprograms
User-defined Overloaded operators

functions
basic structure
function(arguments), which can be stored in a variable
functions are first class objects, hence they can be bound to symbols (or variables), can be passed as arguments, and can be given different names

lazy implementations of function arguments
arguments are boxed into promises which contain the expression passed as an argument and a reference to the environment
values are evaluated transparently when their value is required

r does not state when promises are forced.
order of evaluation affects side effects (promises)
promises are evaluated aggresively as they do not outlive the function they are passed to
name lookup will force promises in order to determine if the symbol is bound to the function

referential transparency
referentail if any expression is replaced by its result, which does not induce side effects on other values
in r, all function arguments are passed by value, all updates are only visible to specific functions

parameters - specifying default parameter values and a variable number of parameters
passing is done by position or by name
omits parameters with default values
a valid call must have at least one positional parameter

lookup is context sensitive

... argument
arguments after ellipsis must be passed by name
default arguments values can be expressions and evaluated within the same environment as the function body, can use internal variables in the function's body

\iffalse
\subsection{Data Types}
R does not provide direct access to the computer's memory
provides special data structures referred to as objects
which are referred to through symbols or variables
In R, symbols are themselves objects and can be manipulated in the same way as any other object.

r objects are often coerced to different types during computations (implicit), explicit coercion also exists.

Basic types
Vectors - contiguous cells which contains data, accessed by indexing operations

Vectors with multiple elements must have the same classes; in the case that there are different classes, implicit coercion is done. Depends on the easiness of the data type

*three types of objects in the r language:
calls
expressions/statements
names

symbol objects
symbols refer to R objects. the name of any r object is usually a symbol
can be created through the functions as.name and quote
appear as atoms of parsed expressions

expressions objects
expressions contains one or more statements
statement is a syntactically correct collection of tokens
evaluated when explicitly passed to eval

data type of object becomes the type of the variable


<variable> ::= [A-z | a-z | .[A-Z | a-z] ][A-Z|a-z|.|_]*



EXPRESSIONS
SYNTAX
PRECEDENCE RULES
OVERLOADED OPERATIONS

TYPE CONVERSIONS, RELATIONAL AND BOOLEAN EXPRESSIONS

ASSIGNMENT STATEMENTS
PROCEDURE CALLS
CONDITIONAL
ITERATIVE
CONCURRENT
SEQUENTIAL

SUBPROGRAMS
SIMPLE CALL RETURNS
RECURSIVE PROCEDURES
COROUTINES

EXCEPTION HANDLERS
PARAMETER PASSING METHODS
PARAMETERS WHICH ARE SUBPROGRAMS

FUNCTIONS OVERLOADING
GENERIC SUBPROGRAMS
USER DEFINED OVERLOADED OPERATORS

\fi


\section{C++}
\subsection{Purpose and Motivations}
The purpose and motivation for the development of C++ programming language stems from the Ph.D thesis of Bjarne Stroustrup, the
inventor of C++, where he used the Simula 67 language which is accredited as the first programming language to implement 
object-oriented programming. He found it incredibly useful for software development but was deterred from continued use
due to the language being far too slow to be practical. Thus the development of \textit{C with Classes} later to be renamed \textit{C++}.
\subsection{History (Authors, Revisions, Adoption)}
\subsubsection{Early Development}
Happy times my guy
\subsubsection{International Recognition and Standardization}

\subsubsection{Current Development}

\subsection{Language Features}

\subsection{Paradigm(s)}

\subsection{Language Evaluation Criteria}
lots and lots of them my guy 

\end{document}
